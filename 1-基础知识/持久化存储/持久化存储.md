#### 持久化存储介绍

> k8s的持久化包括pv、pvc、storageclass等
>
> k8s上，pod的生命周期可能是很短，它们会被频繁地销毁和创建，自然在容器销毁时，里面运行时新增的数据，如修改的配置及日志文件等也会被清除
>
> 怎么解决这一现象呢，可以用k8s volume来持久化保存容器的数据，volume的生命周期独立于容器，pod中的容器可能被销毁重建，但volume会被保留
>
> 本质上，k8s volume是一个目录，这点和docker volume差不多，当volume被mount到pod上，这个pod中的所有容器都可以访问这个volume，在生产场景中，常用的类型有这几种：
>
> - emptyDir
> - hostPath
> - PersistentVolume(PV) & PersistentVolumeClaim(PVC)
> - StorageClass



#### emptyDir

> emptyDir，它是最基础的volume类型
>
> pod内的容器发生重启不会造成emptyDir里面数据的丢失，但是当pod被重启后，emptyDir数据会丢失，也就是说emptyDir与pod的生命周期是一致的
>
> 在生产中它的最实际最实用的场景是提供pod内多容器的volume数据共享

```shell
【10.0.1.21】
# docker pull swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/nginx:1.27.1
# docker tag  swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/nginx:1.27.1  harbor.alnk.com/public/nginx:1.27.1
# docker push harbor.alnk.com/public/nginx:1.27.1


# mkdir -p /data/k8s-yaml/volume
# cd /data/k8s-yaml/volume
# vi emptydir-web-nginx.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: emptydir-web-nginx
  name: emptydir-web-nginx
  namespace: alnk
spec:
  replicas: 1
  selector:
    matchLabels:
      app: emptydir-web-nginx
  template:
    metadata:
      labels:
        app: emptydir-web-nginx
    spec:
      containers:
      - name: nginx  
        image: harbor.alnk.com/public/nginx:1.27.1
        resources:
          limits:
            cpu: "50m"
            memory: 20Mi
          requests:
            cpu: "50m"
            memory: 20Mi
        volumeMounts:         
          # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
          - name: html-files
            # 将数据挂载到当前这个容器的这个目录下
            mountPath: "/usr/share/nginx/html"	    
      - name: busybox ## 在pod内再跑一个容器，每秒把当时时间写到nginx默认页面上
        image: harbor.alnk.com/public/busybox:latest
        args:
        - /bin/sh
        - -c
        - >
           while :; do
             if [ -f /html/index.html ];then
               echo "[$(date +%F\ %T)] hello" > /html/index.html
               sleep 1
             else
               touch /html/index.html
             fi
           done
        volumeMounts:
          # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
          - name: html-files 
            # 将数据挂载到当前这个容器的这个目录下
            mountPath: "/html"
      # 在pod内声明一个卷
      volumes:
        # 卷名称，上面volumeMounts卷挂载需要和这个卷的名称保持一致
        - name: html-files   
          # 卷类型 这就是使用emptyDir卷类型了
          emptyDir: 
            # 将文件写入内存中保存，这样速度会很快，
            # 配置为medium: ""，就是代表默认的使用本地磁盘空间来进行存储
            medium: Memory 
            # 因为内存比较珍贵，注意限制使用大小
            sizeLimit: 10Mi  

---
# service
kind: Service
apiVersion: v1
metadata:
  name: emptydir-web-nginx
  namespace: alnk
  labels:
    app: emptydir-web-nginx
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    name: http
  selector:
    app: emptydir-web-nginx

【10.0.1.201】
# kubectl apply -f http://k8s-yaml.alnk.com/volume/emptydir-web-nginx.yaml

# kubectl -n alnk get svc,pod 
# kubectl -n alnk get svc,pod
NAME                              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/emptydir-web-nginx        ClusterIP   10.68.129.129   <none>        80/TCP    20s

NAME                                          READY   STATUS    RESTARTS        AGE
pod/emptydir-web-nginx-6c9bf6f96d-jvjjp       2/2     Running   0               20s

# curl 10.68.129.129
[2024-11-05 14:26:11] hello
# curl 10.68.129.129
[2024-11-05 14:26:14] hello

## 删除测试资源
# kubectl delete -f http://k8s-yaml.alnk.com/volume/emptydir-web-nginx.yaml
```

> 原理
>
> ```shell
> 【10.0.1.201】
> # kubectl -n alnk describe pod emptydir-web-nginx-6c9bf6f96d-jvjjp
> Node:         10.0.1.203/10.0.1.203
> 
> nginx:
> Container ID:  docker://df96ea79554550e1dc6c44bda1b3dde033b7a5fae0476a94cb37f7bd80885b39
> 
> busybox:
> Container ID:  docker://445f6ee2134a4c23bd064c22e956d3578094903290ea3609f25c40b54c4d83f7
> 
> 【10.0.1.203】
> # docker inspect df96ea79554550e1dc6c44bda1b3dde033b7a5fae0476a94cb37f7bd80885b39|grep volume|grep html
> "/var/lib/kubelet/pods/6eab9984-8a61-4254-8149-6d358396d91a/volumes/kubernetes.io~empty-dir/html-files:/usr/share/nginx/html",
> "Source": "/var/lib/kubelet/pods/6eab9984-8a61-4254-8149-6d358396d91a/volumes/kubernetes.io~empty-dir/html-files"
> 
> 
> # docker inspect 445f6ee2134a4c23bd064c22e956d3578094903290ea3609f25c40b54c4d83f7|grep volume|grep html
> "/var/lib/kubelet/pods/6eab9984-8a61-4254-8149-6d358396d91a/volumes/kubernetes.io~empty-dir/html-files:/html",
> "Source": "/var/lib/kubelet/pods/6eab9984-8a61-4254-8149-6d358396d91a/volumes/kubernetes.io~empty-dir/html-files",
> 
> 
> # ll /var/log/containers/|grep emptydir-web-nginx
> lrwxrwxrwx  1 root root     105 Nov  5 22:25 emptydir-web-nginx-6c9bf6f96d-jvjjp_alnk_busybox-445f6ee2134a4c23bd064c22e956d3578094903290ea3609f25c40b54c4d83f7.log -> /var/log/pods/alnk_emptydir-web-nginx-6c9bf6f96d-jvjjp_6eab9984-8a61-4254-8149-6d358396d91a/busybox/0.log
> 
> lrwxrwxrwx  1 root root     103 Nov  5 22:25 emptydir-web-nginx-6c9bf6f96d-jvjjp_alnk_nginx-df96ea79554550e1dc6c44bda1b3dde033b7a5fae0476a94cb37f7bd80885b39.log -> /var/log/pods/alnk_emptydir-web-nginx-6c9bf6f96d-jvjjp_6eab9984-8a61-4254-8149-6d358396d91a/nginx/0.log
> 
> ```



#### hostPath

> hostPath Volume 的作用是将容器运行的node上已经存在文件系统目录给mount到pod的容器。
>
> 在生产中大部分应用是是不会直接使用hostPath的，因为我们并不关心Pod在哪台node上运行，而hostPath又恰好增加了pod与node的耦合，限制了pod的使用，
>
> 这里只作一下了解，知道有这个东西存在即可，一般只是一些安装服务会用到，比如下面截取了网络插件flannel的部分volume配置
>
> ```shell
> # kubectl -n kube-system get daemonsets.apps kube-flannel-ds -o yaml
>         volumeMounts:
>         - mountPath: /etc/cni/net.d
>           name: cni
> 
>       volumes:
>       - hostPath:
>           path: /etc/cni/net.d
>           type: ""
>         name: cni
> ```



#### pv&pvc

> Volume里面在生产中用的最多的PersistentVolume(持久卷，简称PV)和 PersistentVolumeClaim(持久卷消费，简称PVC)
>
> 通常在企业中，Volume是由存储系统的管理员来维护，他们来提供pv，pv具有持久性，生命周期独立于Pod；Pod则是由应用的开发人员来维护，如果要进行一卷挂载，那么就写一个pvc来消费pv就可以了，K8s会查找并提供满足条件的pv
>
> 有了pvc，在K8s进行卷挂载就只需要考虑要多少容量了，而不用关心真正的空间是用什么存储系统做的等一些底层细节信息，pv这些只有存储管理员才应用去关心它
>
> K8s支持多种类型的pv，生产中常用的NFS（在云上的话就用NAS），生产中如果对存储要求不是太高的话，建议就用NFS，这样出问题也比较容易解决，如果有性能需求，可以看看rook的ceph，以及Rancher的Longhorn
>

```shell
【10.0.1.21】
## 部署nfs-server
# mkdir -p /data/nfs-volume
# sudo apt install nfs-kernel-server -y

# vi /etc/exports
/data/nfs-volume *(rw,sync,no_root_squash)

# systemctl restart rpcbind.service
# systemctl restart nfs-kernel-server.service 
# systemctl restart nfs-utils.service 
# systemctl restart nfs-server.service
# systemctl enable nfs-kernel-server.service

# showmount -e 10.0.1.21
Export list for 10.0.1.21:
/data/nfs-volume/prometheus *

# mkdir /data/nfs-volume/pv1
# chown -R nobody.nogroup /data/nfs-volume

### 准备pv
# cd /data/k8s-yaml/volume
# vi pv1.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  #namespace: alnk #pv属于集群资源，不需要指定名称空间
  name: pv1
  labels:
    type: test-claim    # 这里建议打上一个独有的标签，方便在多个pv的时候方便提供pvc选择挂载
spec:
  capacity:
    storage: 1Gi # <----------  1
  accessModes:
    - ReadWriteOnce     # <----------  2
  persistentVolumeReclaimPolicy: Recycle     # <----------  3
  storageClassName: nfs     # <----------  4
  nfs:
    path: /data/nfs-volume/pv1     # <----------  5
    server: 10.0.1.21

### 注释
# 1. capacity指定PV的容量为1G

# 2. accessModes 指定访问模式为 ReadWriteOnce，支持的访问模式有：
# ReadWriteOnce – PV 能以 read-write 模式 mount 到单个节点。
# ReadOnlyMany – PV 能以 read-only 模式 mount 到多个节点。
# ReadWriteMany – PV 能以 read-write 模式 mount 到多个节点。

# 3. persistentVolumeReclaimPolicy 指定当 PV 的回收策略为 Recycle，支持的策略有：
# Retain – 需要管理员手工回收。
# Recycle – 清除 PV 中的数据，效果相当于执行 rm -rf /thevolume/*。
# Delete – 删除 Storage Provider 上的对应存储资源，例如 AWS EBS、GCE PD、Azure Disk、OpenStack Cinder Volume 等。

# 4. storageClassName 指定 PV 的 class 为 nfs。相当于为 PV 设置了一个分类，PVC 可以指定 class 申请相应 class 的 PV。

# 5. 指定 PV 在 NFS 服务器上对应的目录，这里注意，需要手动先创建好这个目录并授权好，不然后面挂载会提示目录不存在 mkdir /nfsdata/pv1 && chown -R nobody.nogroup /nfsdata


## 准备pvc
# vi pvc1.yaml 
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pvc1
  namespace: alnk
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: nfs
  selector:
    matchLabels:
      type: test-claim


## 准备pod服务来挂载这个pvc
# vi emptydir-web-nginx-pvc.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: emptydir-web-nginx
  name: emptydir-web-nginx
  namespace: alnk
spec:
  replicas: 1
  selector:
    matchLabels:
      app: emptydir-web-nginx
  template:
    metadata:
      labels:
        app: emptydir-web-nginx
    spec:
      containers:
      - name: nginx  
        image: harbor.alnk.com/public/nginx:1.27.1
        resources:
          limits:
            cpu: "50m"
            memory: 20Mi
          requests:
            cpu: "50m"
            memory: 20Mi
        volumeMounts:         
          # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
          - name: html-files
            # 将数据挂载到当前这个容器的这个目录下
            mountPath: "/usr/share/nginx/html"	    
      - name: busybox ## 在pod内再跑一个容器，每秒把当时时间写到nginx默认页面上
        image: harbor.alnk.com/public/busybox:latest
        args:
        - /bin/sh
        - -c
        - >
           while :; do
             if [ -f /html/index.html ];then
               echo "[$(date +%F\ %T)] hello" > /html/index.html
               sleep 1
             else
               touch /html/index.html
             fi
           done
        volumeMounts:
          # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
          - name: html-files 
            # 将数据挂载到当前这个容器的这个目录下
            mountPath: "/html"
      # 在pod内声明一个卷
      volumes:
        #卷名称，上面volumeMounts卷挂载需要和这个卷的名称保持一致
        - name: html-files 
          persistentVolumeClaim:  # 卷类型使用pvc,同时下面名称处填先创建好的pvc1
            claimName: pvc1

---
# service
kind: Service
apiVersion: v1
metadata:
  name: emptydir-web-nginx
  namespace: alnk
  labels:
    app: emptydir-web-nginx
spec:
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    name: http
  selector:
    app: emptydir-web-nginx



【10.0.1.201】
# kubectl apply -f http://k8s-yaml.alnk.com/volume/pv1.yaml
# kubectl apply -f http://k8s-yaml.alnk.com/volume/pvc1.yaml 
# kubectl apply -f http://k8s-yaml.alnk.com/volume/emptydir-web-nginx-pvc.yaml

# kubectl -n alnk get svc
NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
emptydir-web-nginx        ClusterIP   10.68.123.251   <none>        80/TCP    83s

# curl 10.68.123.251
[2024-11-05 15:19:42] hello
# curl 10.68.123.251
[2024-11-05 15:19:44] hello
```

>  `如何回收pvc && pv`
>
> ```shell
> 【10.0.1.21】
> # ll /data/nfs-volume/pv1/
> -rw-r--r-- 1 root   root      28 Nov  5 23:22 index.html
> 
> 【10.0.1.201】
> # 这里删除时会一直卡着，我们按ctrl+c看看怎么回事
> #  kubectl -n alnk delete pvc pvc1
> persistentvolumeclaim "pvc1" deleted
> 
> 
> # 看下pvc发现STATUS是Terminating删除中的状态，分析是因为服务pod还在占用这个pvc使用中
> # kubectl -n alnk get pvc
> NAME   STATUS        VOLUME   CAPACITY   ACCESS MODES   STORAGECLASS   AGE
> pvc1   Terminating   pv1      1Gi        RWO            nfs            21m
> 
> # 先删除这个pod
> # kubectl delete -f http://k8s-yaml.alnk.com/volume/emptydir-web-nginx-pvc.yam
> 
> # 再看先删除的pvc已经没有了
> # kubectl -n alnk get pvc
> No resources found in default namespace.
> 
> # 根据先前创建pv时的数据回收策略为Recycle – 清除PV中的数据，这时果然先创建的index.html已经被删除了，在生产中要尤其注意这里的模式，注意及时备份数据，注意及时备份数据，注意及时备份数据
> # ll /data/nfs-volume/pv1/
> total 0
> 
> # 虽然此时pv是可以再次被pvc来消费的，但根据生产的经验，建议在删除pvc时，也同时把它消费的pv一并删除，然后再重启创建都是可以的
> 
> ```



#### StorageClass

> 利用nfs-client-provisioner来生成一个基于nfs的StorageClass，部署配置yaml配置如下，保持为nfs-sc.yaml

`nfs-sc.yaml`

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  namespace: kube-system

---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kube-system 
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io

---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: nfs-provisioner-01
  namespace: kube-system
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-provisioner-01
  template:
    metadata:
      labels:
        app: nfs-provisioner-01
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: harbor.alnk.com/public/nfs-subdir-external-provisioner:v4.0.2
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: nfs-provisioner-01  # 此处供应者名字供storageclass调用
            - name: NFS_SERVER
              value: 10.0.1.21   # 填入NFS的地址
            - name: NFS_PATH
              value: /data/nfs-volume   # 填入NFS挂载的目录
      volumes:
        - name: nfs-client-root
          nfs:
            server: 10.0.1.21   # 填入NFS的地址
            path: /data/nfs-volume   # 填入NFS挂载的目录

---
# use aliyun's nas need configure: https://help.aliyun.com/document_detail/130727.html?spm=a2c4g.11174283.6.715.1aad2ceeUrijYZ
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-alnk
provisioner: nfs-provisioner-01
# Supported policies: Delete、 Retain ， default is Delete
reclaimPolicy: Retain
```



```shell
【10.0.1.21】
# docker pull swr.cn-north-4.myhuaweicloud.com/ddn-k8s/k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2

# docker tag swr.cn-north-4.myhuaweicloud.com/ddn-k8s/k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2 harbor.alnk.com/public/nfs-subdir-external-provisioner:v4.0.2

# docker push harbor.alnk.com/public/nfs-subdir-external-provisioner:v4.0.2


# cd /data/k8s-yaml/volume
# vi nfs-sc.yaml

【10.0.1.201】
# kubectl apply -f http://k8s-yaml.alnk.com/volume/nfs-sc.yaml

# kubectl -n kube-system get pod
nfs-provisioner-01-8c57845cc-kxjq9           1/1     Running     0               20s

# kubectl get sc
nfs-alnk   nfs-provisioner-01   Retain Immediate   false   70s
```



> 基于StorageClass创建一个pvc，看看动态生成的pv是什么效果
>
> ```shell
> 【10.0.1.21】
> # cd /data/k8s-yaml/volume
> # vi pvc-sc.yaml 
> kind: PersistentVolumeClaim
> apiVersion: v1
> metadata:
>   name: pvc-sc
>   namespace: alnk
> spec:
>   storageClassName: nfs-alnk
>   accessModes:
>     - ReadWriteMany
>   resources:
>     requests:
>       storage: 1Mi
>       
> 
> # 将pvc的名称换成上面的pvc-sc
> # vi emptydir-web-nginx-pvc-sc.yaml
> ---
> apiVersion: apps/v1
> kind: Deployment
> metadata:
>   labels:
>     app: emptydir-web-nginx
>   name: emptydir-web-nginx
>   namespace: alnk
> spec:
>   replicas: 1
>   selector:
>     matchLabels:
>       app: emptydir-web-nginx
>   template:
>     metadata:
>       labels:
>         app: emptydir-web-nginx
>     spec:
>       containers:
>       - name: nginx  
>         image: harbor.alnk.com/public/nginx:1.27.1
>         resources:
>           limits:
>             cpu: "50m"
>             memory: 20Mi
>           requests:
>             cpu: "50m"
>             memory: 20Mi
>         volumeMounts:         
>           # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
>           - name: html-files
>             # 将数据挂载到当前这个容器的这个目录下
>             mountPath: "/usr/share/nginx/html"	    
>       - name: busybox ## 在pod内再跑一个容器，每秒把当时时间写到nginx默认页面上
>         image: harbor.alnk.com/public/busybox:latest
>         args:
>         - /bin/sh
>         - -c
>         - >
>            while :; do
>              if [ -f /html/index.html ];then
>                echo "[$(date +%F\ %T)] hello" > /html/index.html
>                sleep 1
>              else
>                touch /html/index.html
>              fi
>            done
>         volumeMounts:
>           # 注意这里的名称和卷声明的名称保持一样，这样才能相互进行访问
>           - name: html-files 
>             # 将数据挂载到当前这个容器的这个目录下
>             mountPath: "/html"
>       # 在pod内声明一个卷
>       volumes:
>         #卷名称，上面volumeMounts卷挂载需要和这个卷的名称保持一致
>         - name: html-files 
>           persistentVolumeClaim:  # 卷类型使用pvc,同时下面名称处填先创建好的pvc1
>             claimName: pvc-sc
> 
> ---
> # service
> kind: Service
> apiVersion: v1
> metadata:
>   name: emptydir-web-nginx
>   namespace: alnk
>   labels:
>     app: emptydir-web-nginx
> spec:
>   ports:
>   - protocol: TCP
>     port: 80
>     targetPort: 80
>     name: http
>   selector:
>     app: emptydir-web-nginx
>     
>      
> 【10.0.1.201】
> # kubectl apply -f http://k8s-yaml.alnk.com/volume/pvc-sc.yaml 
> # kubectl -n alnk get pvc
> pvc-sc Bound pvc-8a3ddcb7-1829-4d18-8f8f-0d02e9e2e6a8   1Mi RWX nfs-alnk       29s
> # kubectl -n alnk get pv
> pvc-8a3ddcb7-1829-4d18-8f8f-0d02e9e2e6a8 1Mi RWX Retain Bound alnk/pvc-sc nfs-alnk
> 
> # kubectl apply -f http://k8s-yaml.alnk.com/volume/emptydir-web-nginx-pvc-sc.yaml
> 
> # kubectl -n alnk get svc
> emptydir-web-nginx        ClusterIP   10.68.99.217   <none>        80/TCP    35s
> # curl 10.68.99.217
> [2024-11-05 15:54:55] hello
> 
> 
> 【10.0.1.21】
> # 这里注意下，因为是动态生成的pv，所以它的目录基于是一串随机字符串生成的
> # ll /data/nfs-volume/
> drwxrwxrwx 2 root   root    4096 Nov  5 23:54 alnk-pvc-sc-pvc-8a3ddcb7-1829-4d18-8f8f-0d02e9e2e6a8/
> ```

